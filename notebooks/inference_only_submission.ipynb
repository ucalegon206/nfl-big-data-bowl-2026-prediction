{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup (no network calls)\n",
    "import os\n",
    "import sys\n",
    "# Ensure Kaggle dataset path for files uploaded as a dataset\n",
    "sys.path.insert(0, '/kaggle/input/for_kaggle')\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Python:', sys.version)\n",
    "print('CWD:', Path.cwd())\n",
    "\n",
    "# Try to add repository code to path if present in working dir or parent dirs\n",
    "added = False\n",
    "p = Path.cwd()\n",
    "for _ in range(5):\n",
    "    if (p / 'scripts' / 'load_data.py').exists():\n",
    "        sys.path.insert(0, str(p))\n",
    "        added = True\n",
    "        repo_root = p\n",
    "        break\n",
    "    p = p.parent\n",
    "if not added and Path('/kaggle/input').exists():\n",
    "    # common Kaggle input location: try to find a dataset folder that looks like this repo\n",
    "    candidates = list(Path('/kaggle/input').glob('*nfl*'))\n",
    "    if candidates:\n",
    "        repo_root = candidates[0]\n",
    "        sys.path.insert(0, str(repo_root))\n",
    "        added = True\n",
    "\n",
    "print('Repo root added to sys.path:' , added)\n",
    "\n",
    "# Import local helpers (these are safe: they do not perform network calls)\n",
    "try:\n",
    "    from scripts.load_data import load_test, load_test_input\n",
    "    from features import transform_for_inference, add_time_lag_features\n",
    "except Exception as e:\n",
    "    print('Failed to import local helpers:', e)\n",
    "    print('Ensure this notebook has the project files (scripts/, features.py, models/) available in the working dir or uploaded as a Kaggle dataset.')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c164067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load saved model (joblib)\n",
    "model_path = Path('models') / 'best_model.pkl'\n",
    "# fallback to common Kaggle dataset path if model not in working dir\n",
    "if not model_path.exists() and Path('/kaggle/input').exists():\n",
    "    candidates = list(Path('/kaggle/input').glob('*nfl*'))\n",
    "    if candidates:\n",
    "        f = candidates[0] / 'models' / 'best_model.pkl'\n",
    "        if f.exists():\n",
    "            model_path = f\n",
    "\n",
    "print('Loading model from', model_path)\n",
    "if not model_path.exists():\n",
    "    raise FileNotFoundError(f'Model not found at {model_path}. Upload `models/best_model.pkl` to the notebook working directory or attach as dataset.')\n",
    "\n",
    "meta = joblib.load(model_path)\n",
    "feat_cols = meta['feature_columns']\n",
    "mx = meta['models']['x']\n",
    "my = meta['models']['y']\n",
    "print('Loaded model with', len(feat_cols), 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load test files (local or /kaggle/input fallback)\n",
    "def _load_file_local_or_input(name):\n",
    "    p = Path(name)\n",
    "    if p.exists():\n",
    "        return pd.read_csv(p)\n",
    "    if Path('/kaggle/input').exists():\n",
    "        candidates = list(Path('/kaggle/input').glob('*nfl*'))\n",
    "        if candidates:\n",
    "            q = candidates[0] / name\n",
    "            if q.exists():\n",
    "                return pd.read_csv(q)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "print('Loading test_input.csv and test.csv...')\n",
    "test_input = _load_file_local_or_input('test_input.csv')\n",
    "test = _load_file_local_or_input('test.csv')\n",
    "\n",
    "print('test_input rows:', len(test_input))\n",
    "print('test rows:', len(test))\n",
    "if test.empty or test_input.empty:\n",
    "    raise FileNotFoundError('test.csv or test_input.csv not found. Upload them to the notebook working directory or attach as dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d489c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prepare test features and predict\n",
    "# Merge and add time-lag features like in training\n",
    "df = pd.merge(test, test_input, on=['game_id','play_id','nfl_id','frame_id'], how='left', suffixes=(None,'_in'))\n",
    "df = add_time_lag_features(df)\n",
    "X_pred = transform_for_inference(df, feat_cols, meta.get('player_position_values', None))\n",
    "print('Prepared feature matrix shape:', X_pred.shape)\n",
    "\n",
    "# Make predictions\n",
    "px = mx.predict(X_pred)\n",
    "py = my.predict(X_pred)\n",
    "print('Predictions made:', len(px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Save submission CSV\n",
    "submission = pd.DataFrame({'x': px, 'y': py})\n",
    "submission_path = Path('submission_best_model_OFFICIAL.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print('Saved submission to', submission_path, 'rows:', len(submission))\n",
    "\n",
    "# Quick validation\n",
    "assert not submission.isna().any().any(), 'Submission contains NaNs'\n",
    "assert np.isfinite(submission.values).all(), 'Submission contains non-finite values'\n",
    "print('Submission validation passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10215b",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Run this notebook with Internet disabled in Kaggle Notebook Settings before executing.\n",
    "- If you need me to attach the published notebook to a submission, run it with Internet disabled, publish the executed version, then upload the CSV and choose this published notebook in the Kaggle submission UI.\n",
    "- If any cell errors, copy the cell number (1..5) and the full traceback and I will debug it for you."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
