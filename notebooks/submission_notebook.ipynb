{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ea06d4",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Add repo to path for imports\n",
    "repo_root = Path('/kaggle/input/nfl-big-data-bowl-2026-prediction') if Path('/kaggle/input').exists() else Path('.')\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "print(f'Repo root: {repo_root}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4c696",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef44ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "from scripts.load_data import load_all_inputs, load_all_outputs\n",
    "from features import add_time_lag_features, prepare_features\n",
    "\n",
    "print('Loading training inputs and outputs...')\n",
    "X = load_all_inputs('train')\n",
    "y = load_all_outputs('train')\n",
    "\n",
    "print(f'Inputs: {len(X):,} rows')\n",
    "print(f'Outputs: {len(y):,} rows')\n",
    "print(f'Input columns: {X.columns.tolist()}')\n",
    "print(f'Output columns: {y.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb558590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge inputs and outputs\n",
    "print('Merging training data...')\n",
    "merged = X.merge(y, on=['game_id','play_id','nfl_id','frame_id'], how='inner', suffixes=(None,'_target'))\n",
    "print(f'Merged rows: {len(merged):,}')\n",
    "print(f'Merged shape: {merged.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8cc7b",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time-lag features (velocity, acceleration trends)\n",
    "print('Adding time-lag features...')\n",
    "merged = add_time_lag_features(merged)\n",
    "\n",
    "# Prepare engineered features (ball-relative, normalized coords, etc.)\n",
    "print('Preparing engineered features...')\n",
    "feat_df, feat_cols = prepare_features(merged)\n",
    "\n",
    "print(f'Feature columns ({len(feat_cols)}): {feat_cols}')\n",
    "print(f'Feature DataFrame shape: {feat_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c38c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data (remove NaNs)\n",
    "mask = feat_df[feat_cols].notnull().all(axis=1)\n",
    "feat_df_clean = feat_df[mask].reset_index(drop=True)\n",
    "merged_clean = merged.loc[mask].reset_index(drop=True)\n",
    "\n",
    "print(f'Rows after removing NaNs: {len(feat_df_clean):,}')\n",
    "print(f'Rows removed: {len(feat_df) - len(feat_df_clean):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec316e",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d04647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data (sample for speed if needed)\n",
    "X_all = feat_df_clean[feat_cols].copy()\n",
    "y_x = merged_clean['x_target'].copy()\n",
    "y_y = merged_clean['y_target'].copy()\n",
    "\n",
    "# Sample if dataset is too large\n",
    "MAX_ROWS = 200_000\n",
    "if len(X_all) > MAX_ROWS:\n",
    "    print(f'Sampling {MAX_ROWS} rows for training (from {len(X_all):,})')\n",
    "    idx = np.random.RandomState(42).choice(len(X_all), size=MAX_ROWS, replace=False)\n",
    "    X_all = X_all.iloc[idx].reset_index(drop=True)\n",
    "    y_x = y_x.iloc[idx].reset_index(drop=True)\n",
    "    y_y = y_y.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, yx_train, yx_val, yy_train, yy_val = train_test_split(\n",
    "    X_all, y_x, y_y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training set: {len(X_train):,} rows')\n",
    "print(f'Validation set: {len(X_val):,} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train x regressor\n",
    "print('Training x-coordinate regressor...')\n",
    "best_params_x = {'learning_rate': 0.2, 'max_iter': 400, 'max_depth': 5, 'max_bins': 255, 'min_samples_leaf': 100}\n",
    "mx = HistGradientBoostingRegressor(**best_params_x, random_state=42)\n",
    "mx.fit(X_train, yx_train)\n",
    "print('✓ x-regressor trained')\n",
    "\n",
    "# Train y regressor\n",
    "print('Training y-coordinate regressor...')\n",
    "best_params_y = {'learning_rate': 0.1, 'max_iter': 400, 'max_depth': 8, 'max_bins': 127, 'min_samples_leaf': 100}\n",
    "my = HistGradientBoostingRegressor(**best_params_y, random_state=42)\n",
    "my.fit(X_train, yy_train)\n",
    "print('✓ y-regressor trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77315d1d",
   "metadata": {},
   "source": [
    "## 5. Validation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65931efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "px = mx.predict(X_val)\n",
    "py = my.predict(X_val)\n",
    "\n",
    "rmse_x = np.sqrt(mean_squared_error(yx_val, px))\n",
    "rmse_y = np.sqrt(mean_squared_error(yy_val, py))\n",
    "combined_rmse = np.sqrt((rmse_x**2 + rmse_y**2)/2)\n",
    "\n",
    "print(f'Validation Results:')\n",
    "print(f'  RMSE x: {rmse_x:.4f}')\n",
    "print(f'  RMSE y: {rmse_y:.4f}')\n",
    "print(f'  Combined RMSE: {combined_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0721f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction sanity checks\n",
    "print('Prediction Validation:')\n",
    "print(f'  x predictions - min: {px.min():.2f}, max: {px.max():.2f}, mean: {px.mean():.2f}')\n",
    "print(f'  y predictions - min: {py.min():.2f}, max: {py.max():.2f}, mean: {py.mean():.2f}')\n",
    "print(f'  No NaNs in x: {not np.isnan(px).any()}')\n",
    "print(f'  No NaNs in y: {not np.isnan(py).any()}')\n",
    "print(f'  All finite x: {np.isfinite(px).all()}')\n",
    "print(f'  All finite y: {np.isfinite(py).all()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d7e82",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and metadata\n",
    "meta = {\n",
    "    'feature_columns': feat_cols,\n",
    "    'models': {'x': mx, 'y': my},\n",
    "    'best_params': {'x': best_params_x, 'y': best_params_y},\n",
    "    'player_position_values': merged_clean['player_position'].dropna().unique().tolist()\n",
    "}\n",
    "\n",
    "model_path = Path('models/best_model.pkl')\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(meta, model_path)\n",
    "\n",
    "print(f'Model saved to {model_path}')\n",
    "print(f'Model size: {model_path.stat().st_size / 1024 / 1024:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028665f8",
   "metadata": {},
   "source": [
    "## 7. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b88b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "from scripts.load_data import load_test, load_test_input\n",
    "from features import transform_for_inference\n",
    "\n",
    "print('Loading test data...')\n",
    "test = load_test('.')\n",
    "test_input = load_test_input('.')\n",
    "\n",
    "print(f'Test rows: {len(test):,}')\n",
    "print(f'Test input rows: {len(test_input):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfe69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for prediction\n",
    "df = pd.merge(test, test_input, on=['game_id','play_id','nfl_id','frame_id'], how='left', suffixes=(None,'_in'))\n",
    "df = add_time_lag_features(df)\n",
    "feat_df_test, _ = prepare_features(df)\n",
    "\n",
    "# Transform for inference\n",
    "X_pred = transform_for_inference(df, feat_cols, meta.get('player_position_values', None))\n",
    "\n",
    "print(f'Test features prepared: {X_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print('Making predictions...')\n",
    "px_test = mx.predict(X_pred)\n",
    "py_test = my.predict(X_pred)\n",
    "\n",
    "print(f'Generated {len(px_test):,} predictions')\n",
    "print(f'Predictions - x range: [{px_test.min():.2f}, {px_test.max():.2f}]')\n",
    "print(f'Predictions - y range: [{py_test.min():.2f}, {py_test.max():.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame (only x, y columns as required)\n",
    "submission = pd.DataFrame({\n",
    "    'x': px_test,\n",
    "    'y': py_test\n",
    "})\n",
    "\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "print(f'Submission columns: {submission.columns.tolist()}')\n",
    "print(f'\\nFirst 5 rows:')\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate submission\n",
    "print('Submission Validation:')\n",
    "print(f'  Shape: {submission.shape} (expected: (5837, 2))')\n",
    "print(f'  Has NaNs: {submission.isna().any().any()} (expected: False)')\n",
    "print(f'  All finite: {np.isfinite(submission.values).all()} (expected: True)')\n",
    "print(f'  Column dtypes: {submission.dtypes.tolist()}')\n",
    "\n",
    "if submission.shape[0] == 5837 and not submission.isna().any().any() and np.isfinite(submission.values).all():\n",
    "    print('\\n✅ Submission VALID and ready for upload!')\n",
    "else:\n",
    "    print('\\n❌ Submission has issues - review above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2146198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_path = Path('submission_best_model_OFFICIAL.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f'Submission saved to: {submission_path}')\n",
    "print(f'File size: {submission_path.stat().st_size / 1024:.2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609710a",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "### Architecture\n",
    "- **Model Type**: HistGradientBoostingRegressor (separate for x and y)\n",
    "- **Algorithm**: Histogram-based gradient boosting (fast, efficient)\n",
    "- **Training Data**: 560k+ labeled frames from 18 weeks of 2023 NFL season\n",
    "\n",
    "### Features (12 total)\n",
    "1. **Raw Features**: x, y, s (speed), a (acceleration), dir (direction), o (orientation)\n",
    "2. **Normalized Features**: dir_sin, dir_cos (trigonometric transformation)\n",
    "3. **Context Features**: num_frames_output, absolute_yardline_number, player_pos_code\n",
    "4. **Ball-Relative**: dx_ball, dy_ball, dist_ball (distance/direction to ball landing)\n",
    "5. **Time-Lag Features**: (dx, dy, vx, vy lags for velocity/acceleration trends)\n",
    "\n",
    "### Hyperparameters\n",
    "**X Regressor**:\n",
    "- learning_rate: 0.2\n",
    "- max_iter: 400\n",
    "- max_depth: 5\n",
    "- max_bins: 255\n",
    "- min_samples_leaf: 100\n",
    "\n",
    "**Y Regressor**:\n",
    "- learning_rate: 0.1\n",
    "- max_iter: 400\n",
    "- max_depth: 8\n",
    "- max_bins: 127\n",
    "- min_samples_leaf: 100\n",
    "\n",
    "### Performance\n",
    "- **Validation RMSE (x)**: 3.4677\n",
    "- **Validation RMSE (y)**: 3.4810\n",
    "- **Combined RMSE**: 3.4743\n",
    "\n",
    "### Reproducibility\n",
    "- All code is in the GitHub repository: https://github.com/ucalegon206/nfl-big-data-bowl-2026-prediction\n",
    "- Complete data loading and feature engineering pipeline included\n",
    "- Model trained on publicly available competition data only\n",
    "- No external data or proprietary tools used"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
